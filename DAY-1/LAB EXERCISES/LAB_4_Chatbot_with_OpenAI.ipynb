{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UGUvdILUbzOu"
      },
      "outputs": [],
      "source": [
        "pip install langchain openai==0.28 python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8me0PyYfImr"
      },
      "outputs": [],
      "source": [
        "pip install langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8Zcu0A8dXYT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from langchain import OpenAI\n",
        "from langchain.chains import ConversationChain\n",
        "import openai\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "# Set up the Azure OpenAI API key and endpoint\n",
        "api_key = \"CnlpRiTLzbJSEDTW3i1RcMa0GAkJiHqEe9Rse5mqVHUU0ZeVipvBJQQJ99BIACYeBjFXJ3w3AAAAACOGB28S\"\n",
        "endpoint = \"https://kedar.cognitiveservices.azure.com/\"\n",
        "deployment = \"gpt-35-turbo\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SgjqJ8HYdS4U"
      },
      "outputs": [],
      "source": [
        "print(f\"API Key: {api_key}\")\n",
        "print(f\"Endpoint: {endpoint}\")\n",
        "print(f\"Deployment: {deployment}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure OpenAI client\n",
        "openai.api_type = \"azure\"\n",
        "openai.api_base = endpoint\n",
        "openai.api_version = \"2024-05-01-preview\"  # Adjust the version if needed\n",
        "openai.api_key = api_key"
      ],
      "metadata": {
        "id": "TjbCE4A102ZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cMsJnLtRcHXT"
      },
      "outputs": [],
      "source": [
        "# Define a function to interact with the Azure OpenAI model\n",
        "def chat_with_bot(user_input):\n",
        "    try:\n",
        "        response = openai.ChatCompletion.create(\n",
        "            engine=deployment,\n",
        "            messages=[{\"role\": \"user\", \"content\": user_input},\n",
        "                      {\"role\": \"system\", \"content\": \"You are an expert baker assistant that will help home bakers ask questions about their sourdough bread dough.\"},]\n",
        "        )\n",
        "        return response.choices[0].message['content']\n",
        "    except Exception as e:\n",
        "        print(f\"Error during conversation: {e}\")\n",
        "        return \"Sorry, I couldn't process your request.\"\n",
        "\n",
        "# Example interaction\n",
        "if __name__ == \"__main__\":\n",
        "    user_input = \"When is starter ready to use?\"\n",
        "    response = chat_with_bot(user_input)\n",
        "    print(\"Chatbot Response:\", response)\n",
        "\n",
        "    # Example interactions loop\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() in [\"exit\", \"quit\"]:\n",
        "            break\n",
        "        response = chat_with_bot(user_input)\n",
        "        print(\"Chatbot:\", response)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}